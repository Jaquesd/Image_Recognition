{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17896e4b-2623-4a07-bd40-2df445f6a3c8",
   "metadata": {},
   "source": [
    "# Image Recognition - Logistic Regression\n",
    "---\n",
    "\n",
    "In this two-part project, we first explore image recognition using Logistic Regression. The subsequent segment contrasts this with Torchvision, offering a comparative insight into both methodologies.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366b2909-184b-4f7b-8248-ee21aadaf8b5",
   "metadata": {},
   "source": [
    "![title](header_image.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e83e825-4638-4607-855e-e94d133970c4",
   "metadata": {},
   "source": [
    "Data source for this project - https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "*Recommended to download the file and save in the same directory of the jupyter notebook*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d37aa08-b563-4902-ac1e-a49371685a1d",
   "metadata": {},
   "source": [
    "## Packages and Instalations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca0ad0c-ed64-49c4-a6a0-93e5989d3069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from platform import python_version\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47d9a1e3-baa1-4b91-a869-4d022261352c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.9.13\n",
      "matplotlib: 3.5.2\n",
      "numpy     : 1.21.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# python and package version\n",
    "# install watermark package if do not have -> !pip install -q -U watermark\n",
    "\n",
    "%reload_ext watermark\n",
    "print('Python:', python_version())\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c701ff78-9c54-431d-b3cb-f90f1052575c",
   "metadata": {},
   "source": [
    "## Class for Load, Process and Handle image data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb796fc3-fe9d-4e0e-9257-9d996f64da2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataHandler:\n",
    "    \"\"\"\n",
    "    ImageDataHandler Class:\n",
    "\n",
    "    This class provides functionalities for handling and processing image data \n",
    "    from the CIFAR-10 dataset.\n",
    "\n",
    "    Attributes:\n",
    "    - base_path: Specifies the directory where the CIFAR-10 batch files are located.\n",
    "\n",
    "    Methods:\n",
    "    1. load_data(filename):\n",
    "       - Loads raw image data and their labels from the specified filename.\n",
    "       - Performs basic preprocessing like reshaping and normalization.\n",
    "       - Returns the processed images and their respective labels.\n",
    "\n",
    "    2. format_data(X, Y, v0, v1):\n",
    "       - Filters and formats the image data based on the provided class labels (v0 and v1).\n",
    "       - Returns the filtered and formatted image data and their respective labels.\n",
    "\n",
    "    3. prepare_data(batch_number, start_val, end_val):\n",
    "       - Combines the functionalities of load_data and format_data.\n",
    "       - Loads the specified data batch, then filters and formats it.\n",
    "       - Returns the prepared image data and labels for training or testing purposes.\n",
    "\n",
    "    Usage:\n",
    "    To preprocess the CIFAR-10 image data, instantiate the class and use the \n",
    "    prepare_data method with the desired batch number and label values.\n",
    "\n",
    "    \"\"\" \n",
    "    \n",
    "    \n",
    "    def __init__(self, base_path=\"cifar-10-batches-py/\"):\n",
    "        self.base_path = base_path\n",
    "    \n",
    "    def load_data(self, filename):\n",
    "        # full path of the file\n",
    "        full_path = f\"{self.base_path}{filename}\"\n",
    "        \n",
    "        # Attempt to load the data; handle potential errors\n",
    "        try:\n",
    "            with open(full_path, 'rb') as file:\n",
    "                data = pickle.load(file, encoding='bytes') # This is a byte string\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {e}\")\n",
    "            return None, None\n",
    "\n",
    "        # Load raw image data\n",
    "        # This is a byte string --> byte_string = b'hello' | text_string = 'hello'\n",
    "        raw_images = data[b'data']\n",
    "        \n",
    "        # Convert labels to a numpy array\n",
    "        y = np.array(data[b'labels'])\n",
    "\n",
    "        # Normalize and convert raw images to floating point\n",
    "        raw_float = np.array(raw_images, dtype=float) / 255.0\n",
    "        \n",
    "        # Reshape and reorder axes to get proper image format\n",
    "        images = raw_float.reshape([-1, 3, 32, 32]).transpose([0, 2, 3, 1])\n",
    "        \n",
    "        # Flatten the images for potential use in algorithms that expect flat vectors\n",
    "        X = images.reshape((images.shape[0], 3*32*32))\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def format_data(self, X, Y, v0, v1):\n",
    "        # Determine the maximum between v0 and v1\n",
    "        lg = max(v0, v1)\n",
    "        \n",
    "        # Use numpy to efficiently find indices of labels that match v0 or v1\n",
    "        indices = np.where((Y == v0) | (Y == v1))\n",
    "        \n",
    "        # Extract and format the data based on found indices\n",
    "        X = np.squeeze(np.take(X, indices, axis=0))\n",
    "        Y = np.squeeze(np.floor(np.take(Y, indices, axis=0) / lg))\n",
    "        \n",
    "        return X, Y\n",
    "\n",
    "    def prepare_data(self, batch_number, start_val, end_val):\n",
    "        # Load the data using the specified batch number\n",
    "        x_train, y_train = self.load_data(f\"data_batch_{batch_number}\")\n",
    "        \n",
    "        # If data loading failed, return None values\n",
    "        if x_train is None or y_train is None:\n",
    "            return None, None\n",
    "        \n",
    "        # Format the loaded data based on the specified start and end values\n",
    "        x_train, y_train = self.format_data(x_train, y_train, start_val, end_val)\n",
    "        \n",
    "        return x_train, y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e780de-a371-431f-9612-fe759b3de93d",
   "metadata": {},
   "source": [
    "## Instantiating an Image Handler and creating train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5ca8a44-e2b0-49c0-bec7-5e5f18114d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = ImageDataHandler()\n",
    "bloco_start = 0\n",
    "bloco_end = 3\n",
    "TRAIN_BATCH = 1\n",
    "x_train, y_train = handler.prepare_data(TRAIN_BATCH, bloco_start, bloco_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b8ad76-2808-4b48-96b4-db0fcfd5e089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
