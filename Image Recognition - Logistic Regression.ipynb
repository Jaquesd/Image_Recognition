{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17896e4b-2623-4a07-bd40-2df445f6a3c8",
   "metadata": {},
   "source": [
    "# Image Recognition - Logistic Regression\n",
    "---\n",
    "\n",
    "In this two-part project, we first explore image recognition using Logistic Regression. The subsequent segment contrasts this with Torchvision, offering a comparative insight into both methodologies.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366b2909-184b-4f7b-8248-ee21aadaf8b5",
   "metadata": {},
   "source": [
    "![title](header_image.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e83e825-4638-4607-855e-e94d133970c4",
   "metadata": {},
   "source": [
    "Data source for this project - https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "*Recommended to download the file and save in the same directory of the jupyter notebook*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d37aa08-b563-4902-ac1e-a49371685a1d",
   "metadata": {},
   "source": [
    "## Packages and Instalations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca0ad0c-ed64-49c4-a6a0-93e5989d3069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from platform import python_version\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47d9a1e3-baa1-4b91-a869-4d022261352c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.9.13\n",
      "matplotlib: 3.5.2\n",
      "numpy     : 1.21.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# python and package version\n",
    "# install watermark package if do not have -> !pip install -q -U watermark\n",
    "\n",
    "%reload_ext watermark\n",
    "print('Python:', python_version())\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c701ff78-9c54-431d-b3cb-f90f1052575c",
   "metadata": {},
   "source": [
    "## Class for Load, Process and Handle image data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fcad074a-57b1-48a5-af9c-41c52b2443da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataHandler:\n",
    "    \"\"\"\n",
    "    A class to handle and process image data from the CIFAR-10 dataset.\n",
    "    \n",
    "    Attributes:\n",
    "    - base_path: Directory where CIFAR-10 batch files are stored.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_path=\"cifar-10-batches-py/\"):\n",
    "        \"\"\"\n",
    "        Initialize ImageDataHandler with a base path.\n",
    "        \n",
    "        Args:\n",
    "        - base_path: Path to the CIFAR-10 data.\n",
    "        \"\"\"\n",
    "        self.base_path = base_path\n",
    "    \n",
    "    def load_data(self, filename):\n",
    "        \"\"\"\n",
    "        Load and preprocess the CIFAR-10 image data.\n",
    "        \n",
    "        Args:\n",
    "        - filename: Name of the CIFAR-10 batch file.\n",
    "        \n",
    "        Returns:\n",
    "        - X: Processed image data.\n",
    "        - y: Corresponding labels.\n",
    "        \n",
    "        Steps:\n",
    "        1. Normalize: Convert raw pixel values (0-255) to the range (0-1).\n",
    "        2. Reshape & Transpose: Convert 1D data to 3D format ([height, width, channels]) for visualization.\n",
    "        3. Flatten: Transform data back to 1D format for ML algorithms expecting flat vectors.\n",
    "        \"\"\"\n",
    "        \n",
    "        full_path = f\"{self.base_path}{filename}\"\n",
    "        \n",
    "        try:\n",
    "            with open(full_path, 'rb') as file:\n",
    "                data = pickle.load(file, encoding='bytes')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data: {e}\")\n",
    "            return None, None\n",
    "\n",
    "        raw_images = data[b'data']\n",
    "        y = np.array(data[b'labels'])\n",
    "        raw_float = np.array(raw_images, dtype=float) / 255.0\n",
    "        images = raw_float.reshape([-1, 3, 32, 32]).transpose([0, 2, 3, 1])\n",
    "        X = images.reshape((images.shape[0], 3*32*32))\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "    def format_data(self, X, Y, v0, v1):\n",
    "        \"\"\"\n",
    "        Filter and format data based on specific class labels.\n",
    "        \n",
    "        Args:\n",
    "        - X: Image data.\n",
    "        - Y: Labels.\n",
    "        - v0, v1: Class labels for filtering.\n",
    "        \n",
    "        Returns:\n",
    "        - X: Filtered image data.\n",
    "        - Y: Corresponding labels.\n",
    "        \n",
    "        Steps:\n",
    "        - Identify data points with labels v0 or v1.\n",
    "        - Filter and adjust the data accordingly.\n",
    "        \"\"\"\n",
    "        \n",
    "        lg = max(v0, v1)\n",
    "        indices = np.where((Y == v0) | (Y == v1))\n",
    "        X = np.squeeze(np.take(X, indices, axis=0))\n",
    "        Y = np.squeeze(np.floor(np.take(Y, indices, axis=0) / lg))\n",
    "        \n",
    "        return X, Y\n",
    "\n",
    "    def prepare_data(self, batch_number, start_val, end_val):\n",
    "        \"\"\"\n",
    "        Load and format a specific batch of CIFAR-10 data.\n",
    "        \n",
    "        Args:\n",
    "        - batch_number: CIFAR-10 batch number.\n",
    "        - start_val, end_val: Range for data filtering.\n",
    "        \n",
    "        Returns:\n",
    "        - x_train: Prepared image data.\n",
    "        - y_train: Corresponding labels.\n",
    "        \n",
    "        Steps:\n",
    "        - Load the data using the specified batch number.\n",
    "        - Format the data based on the specified range.\n",
    "        \"\"\"\n",
    "        \n",
    "        x_train, y_train = self.load_data(f\"data_batch_{batch_number}\")\n",
    "        \n",
    "        if x_train is None or y_train is None:\n",
    "            return None, None\n",
    "        \n",
    "        x_train, y_train = self.format_data(x_train, y_train, start_val, end_val)\n",
    "        \n",
    "        return x_train, y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e780de-a371-431f-9612-fe759b3de93d",
   "metadata": {},
   "source": [
    "## Instantiating an Image Handler and Creating train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b5ca8a44-e2b0-49c0-bec7-5e5f18114d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = ImageDataHandler()\n",
    "start_val = 0\n",
    "end_val = 3\n",
    "train_batch = 1\n",
    "x_train, y_train = handler.prepare_data(train_batch, start_val, end_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463db2c7-9e44-49fb-8d3d-0ee6aaf957c4",
   "metadata": {},
   "source": [
    "## Logistic Regression from Scratch\n",
    "\n",
    "Creating a Logistic Regression model from scratch (no framework used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15d8dfc-89a1-46ca-b068-9c6ec95c8d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the Logistic Regression model.\n",
    "        \n",
    "        Attributes:\n",
    "        - beta: Weights for the logistic regression model.\n",
    "        - likelihood_history: List to store the log likelihood values during training.\n",
    "        - iteration_history: List to store iteration counts during training.\n",
    "        \"\"\"\n",
    "        self.beta = None\n",
    "        self.likelihood_history = []\n",
    "        self.iteration_history = []\n",
    "\n",
    "    def _func_log_likelihood(self, beta, X, Y):\n",
    "        \"\"\"\n",
    "        Compute the log likelihood for the current weights (beta).\n",
    "        \n",
    "        Args:\n",
    "        - beta: Current weights of the model.\n",
    "        - X: Feature data.\n",
    "        - Y: Target labels.\n",
    "        \n",
    "        Returns:\n",
    "        - Log likelihood value.\n",
    "        \"\"\"\n",
    "        t = np.dot(X, beta.T)\n",
    "        w = np.subtract(Y, 1)\n",
    "        w = np.dot(w, t)\n",
    "        m = 1 / (1 + np.exp(-t))\n",
    "        z = np.sum(np.log(m))\n",
    "        return w - z\n",
    "\n",
    "    def _calcula_gradiente(self, beta, X, Y):\n",
    "        \"\"\"\n",
    "        Calculate the gradient of the log likelihood with respect to the weights.\n",
    "        \n",
    "        Args:\n",
    "        - beta: Current weights of the model.\n",
    "        - X: Feature data.\n",
    "        - Y: Target labels.\n",
    "        \n",
    "        Returns:\n",
    "        - Gradient values for each weight.\n",
    "        \"\"\"\n",
    "        z = np.subtract(Y, 1)\n",
    "        w = np.exp(np.dot(-X, beta.T))\n",
    "        p = w / (1 + w)\n",
    "        q = z + p\n",
    "        delta = np.dot(q, X)\n",
    "        return delta\n",
    "\n",
    "    def fit(self, X, Y, epsilon, learning_rate, start, end, beta=None, max_iterations=2000):\n",
    "        \"\"\"\n",
    "        Train the Logistic Regression model using Gradient Descent.\n",
    "        \n",
    "        Args:\n",
    "        - X: Feature data.\n",
    "        - Y: Target labels.\n",
    "        - epsilon: Threshold for the gradient descent stopping criteria.\n",
    "        - learning_rate: Learning rate for the gradient descent update rule.\n",
    "        - start: Starting index for the data.\n",
    "        - end: Ending index for the data.\n",
    "        - beta: Initial weights (if provided).\n",
    "        - max_iterations: Maximum number of iterations for gradient descent.\n",
    "        \n",
    "        Updates:\n",
    "        - beta: Learned weights after training.\n",
    "        \"\"\"\n",
    "        X = X[start:end]\n",
    "        Y = Y[start:end]\n",
    "        data_points = X.shape[0]\n",
    "        dimensions = X.shape[1]\n",
    "\n",
    "        if beta is None:\n",
    "            beta = np.zeros(dimensions)\n",
    "\n",
    "        delta = 0\n",
    "        itr = 0\n",
    "        while True:\n",
    "            grad = self._calcula_gradiente(beta, X, Y)\n",
    "            beta += learning_rate * grad\n",
    "            log_likelihood = self._func_log_likelihood(beta, X, Y)\n",
    "            self.likelihood_history.append(log_likelihood)\n",
    "            itr += 1\n",
    "            self.iteration_history.append(itr)\n",
    "            delta = np.linalg.norm(grad)\n",
    "            if delta < epsilon or itr > max_iterations:\n",
    "                break\n",
    "\n",
    "        self.beta = beta\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict using the trained Logistic Regression model.\n",
    "        \n",
    "        Args:\n",
    "        - X: Feature data to make predictions on.\n",
    "        \n",
    "        Returns:\n",
    "        - Predicted labels.\n",
    "        \"\"\"\n",
    "        z = np.dot(X, self.beta)\n",
    "        predY = (1 / (1 + np.exp(-z)))\n",
    "        return np.around(predY)\n",
    "\n",
    "    def evaluate(self, X, Y):\n",
    "        \"\"\"\n",
    "        Evaluate the model's accuracy on provided data.\n",
    "        \n",
    "        Args:\n",
    "        - X: Feature data.\n",
    "        - Y: True labels.\n",
    "        \n",
    "        Prints:\n",
    "        - Model accuracy.\n",
    "        \"\"\"\n",
    "        predY = self.predict(X)\n",
    "        correct = np.sum(predY == Y)\n",
    "        total = len(Y)\n",
    "        accuracy = (correct / total) * 100\n",
    "        print(f\"Acur√°cia do Modelo: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
